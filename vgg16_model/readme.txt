The scripts/notebooks and their purpose are as follows.

features_vgg16.py - This script requires the path to the folder containing images of products.
It then generates feature vector of size 4096 using pre-trained vgg16 model. It stores all of this in a csv file(name vgg16.csv).
This csv file is the dataset upon which these images will be clustered based on values present in their feature vector.
The header of the csv file is like below
image_filename,feature_1,feature_2...........feature_4096
Each following line has the image filename and corresponding feature vector.

pca_kmeans_vgg16.ipynb - This notebook is to use Principal Component Analysis after scaling to reduce dimensions of the dataset(csv file
generated by features_vgg16.py). 90% variance in data needed to be retained and hence the number of principal components required
to retain that is determined in the notebook and then the dataset is tranformed using the determined number of principal
components. This is followed by performing kmeans clustering trying different number of clusters from 50 to 950.
The kmeans model with the highest silhoutte score is selected and the cluster labels along with samples present in the clusters
are stored in a file named cluster_data.pkl

testing_vgg16.ipynb - This notebook is to test the recommendations made by this method. It uses the items previously bought by a 
customer and determines which clusters do those items belong to using cluster_data.pkl and then suggests the recommendations to
be the rest of the samples present in those clusters. Using mean average precision @k as the metric to quantify the model's 
performance.